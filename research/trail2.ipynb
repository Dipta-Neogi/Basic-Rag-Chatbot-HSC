{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b81f8077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\interviews\\\\HSC chatbot\\\\Basic-Rag-Chatbot-HSC\\\\research'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18067608",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbc72cd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\interviews\\\\HSC chatbot\\\\Basic-Rag-Chatbot-HSC'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f396665e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dipta neogi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing missing packages: sentence-transformers, huggingface-hub, python-dotenv, qdrant-client\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "def install_packages():\n",
    "    required = {\n",
    "        'torch': 'torch',\n",
    "        'transformers': 'transformers',\n",
    "        'accelerate': 'accelerate',\n",
    "        'sentence-transformers': 'sentence-transformers',\n",
    "        'langchain': 'langchain',\n",
    "        'huggingface-hub': 'huggingface-hub',\n",
    "        'python-dotenv': 'python-dotenv',\n",
    "        'qdrant-client': 'qdrant_client',\n",
    "        'langchain-community': 'langchain_community'\n",
    "    }\n",
    "    \n",
    "    missing = []\n",
    "    for pkg_name, import_name in required.items():\n",
    "        try:\n",
    "            __import__(import_name)\n",
    "        except ImportError:\n",
    "            missing.append(pkg_name)\n",
    "    \n",
    "    if missing:\n",
    "        print(f\"Installing missing packages: {', '.join(missing)}\")\n",
    "        os.system(f\"pip install {' '.join(missing)}\")\n",
    "\n",
    "install_packages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "146dc2f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting qdrant-client\n",
      "  Using cached qdrant_client-1.15.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: grpcio>=1.41.0 in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from qdrant-client) (1.73.1)\n",
      "Requirement already satisfied: httpx>=0.20.0 in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from httpx[http2]>=0.20.0->qdrant-client) (0.28.1)\n",
      "Requirement already satisfied: numpy>=1.21 in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from qdrant-client) (2.2.6)\n",
      "Collecting portalocker<4.0,>=2.7.0 (from qdrant-client)\n",
      "  Using cached portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
      "Requirement already satisfied: protobuf>=3.20.0 in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from qdrant-client) (5.29.5)\n",
      "Requirement already satisfied: pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8 in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from qdrant-client) (2.11.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.14 in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from qdrant-client) (2.5.0)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\users\\dipta neogi\\appdata\\roaming\\python\\python310\\site-packages (from portalocker<4.0,>=2.7.0->qdrant-client) (311)\n",
      "Requirement already satisfied: anyio in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (4.9.0)\n",
      "Requirement already satisfied: certifi in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.0.9)\n",
      "Requirement already satisfied: idna in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from httpcore==1.*->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (0.16.0)\n",
      "Collecting h2<5,>=3 (from httpx[http2]>=0.20.0->qdrant-client)\n",
      "  Using cached h2-4.2.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting hyperframe<7,>=6.1 (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client)\n",
      "  Using cached hyperframe-6.1.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting hpack<5,>=4.1 (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client)\n",
      "  Using cached hpack-4.1.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant-client) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant-client) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant-client) (4.14.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant-client) (0.4.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from anyio->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from anyio->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.3.1)\n",
      "Using cached qdrant_client-1.15.0-py3-none-any.whl (337 kB)\n",
      "Using cached portalocker-3.2.0-py3-none-any.whl (22 kB)\n",
      "Using cached h2-4.2.0-py3-none-any.whl (60 kB)\n",
      "Using cached hpack-4.1.0-py3-none-any.whl (34 kB)\n",
      "Using cached hyperframe-6.1.0-py3-none-any.whl (13 kB)\n",
      "Installing collected packages: portalocker, hyperframe, hpack, h2, qdrant-client\n",
      "\n",
      "   -------------------------------- ------- 4/5 [qdrant-client]\n",
      "   -------------------------------- ------- 4/5 [qdrant-client]\n",
      "   -------------------------------- ------- 4/5 [qdrant-client]\n",
      "   ---------------------------------------- 5/5 [qdrant-client]\n",
      "\n",
      "Successfully installed h2-4.2.0 hpack-4.1.0 hyperframe-6.1.0 portalocker-3.2.0 qdrant-client-1.15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -egex (e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -egex (e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -egex (e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!\"{sys.executable}\" -m pip install qdrant-client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2df313a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now import everything\n",
    "import torch\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from dotenv import load_dotenv\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from langchain_community.llms import HuggingFacePipeline\n",
    "from langchain.vectorstores import Qdrant\n",
    "from qdrant_client import QdrantClient\n",
    "from huggingface_hub import login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5989375b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Check for GPU\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ec1569e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing PDFs...\n",
      "Created 2524 text chunks\n"
     ]
    }
   ],
   "source": [
    "# 1. PDF Processing\n",
    "def load_pdf_file(data):\n",
    "    loader = DirectoryLoader(data, glob=\"*.pdf\", loader_cls=PyPDFLoader)\n",
    "    return loader.load()\n",
    "\n",
    "def text_split(extracted_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)\n",
    "    return text_splitter.split_documents(extracted_data)\n",
    "\n",
    "print(\"Processing PDFs...\")\n",
    "extracted_data = load_pdf_file(data='Data/')\n",
    "text_chunks = text_split(extracted_data)\n",
    "print(f\"Created {len(text_chunks)} text chunks\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a07a92dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (2.2.2)\n",
      "Collecting sentence-transformers\n",
      "  Using cached sentence_transformers-5.0.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from sentence-transformers) (4.53.3)\n",
      "Requirement already satisfied: tqdm in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from sentence-transformers) (2.7.1)\n",
      "Requirement already satisfied: scikit-learn in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from sentence-transformers) (1.7.1)\n",
      "Requirement already satisfied: scipy in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from sentence-transformers) (1.15.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from sentence-transformers) (0.33.4)\n",
      "Requirement already satisfied: Pillow in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from sentence-transformers) (11.3.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from sentence-transformers) (4.14.1)\n",
      "Requirement already satisfied: filelock in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\dipta neogi\\appdata\\roaming\\python\\python310\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.7.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.7.14)\n",
      "Requirement already satisfied: joblib>=1.2.0 in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Using cached sentence_transformers-5.0.0-py3-none-any.whl (470 kB)\n",
      "Installing collected packages: sentence-transformers\n",
      "  Attempting uninstall: sentence-transformers\n",
      "    Found existing installation: sentence-transformers 2.2.2\n",
      "    Uninstalling sentence-transformers-2.2.2:\n",
      "      Successfully uninstalled sentence-transformers-2.2.2\n",
      "Successfully installed sentence-transformers-5.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -egex (e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -egex (e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -egex (e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!\"{sys.executable}\" -m pip install -U sentence-transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e147b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence-transformers version: 5.0.0\n"
     ]
    }
   ],
   "source": [
    "import sentence_transformers\n",
    "print(\"sentence-transformers version:\", sentence_transformers.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e23f576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings...\n"
     ]
    }
   ],
   "source": [
    "# 2. Embeddings\n",
    "print(\"Loading embeddings...\")\n",
    "embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022c9579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Qdrant...\n"
     ]
    }
   ],
   "source": [
    "# 3. Qdrant Setup (instead of Pinecone)\n",
    "print(\"Initializing Qdrant...\")\n",
    "from langchain.vectorstores import Qdrant\n",
    "\n",
    "collection_name = \"hsc-bot-qdrant2\"\n",
    "\n",
    "docsearch = Qdrant.from_documents(\n",
    "    documents=text_chunks,\n",
    "    embedding=embeddings,\n",
    "    url=\"https://e4e35b2d-339f-4fd1-be49-f757c694232d.us-west-1-0.aws.cloud.qdrant.io:6333\",\n",
    "    api_key=\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3MiOiJtIn0.hET2Ps4DMbkBTIIwOAc5sHHbP704CLyevrk0FGRRYso\",\n",
    "    collection_name=collection_name,\n",
    "    prefer_grpc=False  # set True if your Qdrant cloud instance supports gRPC\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "72f227a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = docsearch.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a85b7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Qwen3-0.6B model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building RAG chain...\n",
      "\n",
      "System ready. Testing with sample query...\n",
      "\n",
      "Question: Who is Nelson Mandela?\n",
      "Answer: System: You are a bilingual assistant that answers questions in both English and Bangla. \n",
      "Follow these rules strictly:\n",
      "\n",
      "1. Language Handling:\n",
      "- Detect the question's language automatically\n",
      "- Respond in the same language as the question\n",
      "- For Bangla queries, respond in authentic Bangla (not transliterated)\n",
      "\n",
      "2. Answer Generation:\n",
      "- Use only the provided context to answer\n",
      "- If the answer isn't in the context, say:\n",
      "  - English: \"I don't have information about this.\"\n",
      "  - Bangla: \"আমার কাছে এই সম্পর্কে কোনো তথ্য নেই।\"\n",
      "- Keep answers concise (2-3 sentences)\n",
      "- For Bangla answers, use proper Bangla grammar and formatting\n",
      "\n",
      "3. Context Usage:\n",
      "- Prioritize information from the retrieved context\n",
      "- Never make up facts not present in the context\n",
      "- Combine information from multiple chunks when needed\n",
      "\n",
      "Examples:\n",
      "English Question: \"What causes diabetes?\"\n",
      "English Answer: \"Diabetes occurs when...\"\n",
      "\n",
      "Bangla Question: \"ডায়াবেটিসের কারণ কী?\"\n",
      "Bangla Answer: \"ডায়াবেটিস হয় যখন...\"\n",
      "\n",
      "Context:\n",
      "together with others has ................... his humble contribution.” \n",
      "[The text on Mandela is written by Andrew Quinn and Jon Herskovitz; Edited by Pascal Fletcher and \n",
      "Angus MacSwan. Source: http://tv.yahoo.com/news/nelson-mandela-apartheid-fighter-president-unifier- \n",
      "105117261.html, accessed on 14/02/2014] \n",
      "2022-2023\n",
      "\n",
      "Imprisoned for nearly three decades for his fight against white minority rule, 5 \n",
      "Mandela never lost his resolve to fight for is people's emancipation. He was \n",
      "determined to bring down apartheid while avoiding a civil war. His prestige and \n",
      "charigma helped him win the support of the world. \n",
      "2022-2023\n",
      "\n",
      "In 1993, Mandela was awarded the Nobel Peace Prize, an honor he shared with \n",
      "F.W. de Klerk, the white South African leader who had freed him from prison three \n",
      "years earlier and negotiated the end of apartheid. \n",
      "Mandela went on to play a prominent role on the world stage as an advocate of \n",
      "human dignity in the face of challenges ranging from political repression to AIDS. \n",
      "He formally left public life in June 2004 before his 86th birthday, telling his\n",
      "Human: Who is Nelson Mandela? \n",
      "Answer: Nelson Mandela is a former South African president who fought against apartheid and is known for his advocacy for human rights and peace.\n",
      "Bangla Answer: মন্ডলেন সার্ট্স এক সার্থক সার্থক প্রধান সার্থক প্রধান প্রধান প্রধান প্রধান প্রধান প্রধান প্রধান প্রধান প্রধান প্রধান প্রধান প্রধান প্রধান প্রধান প্রধান প্রধান প্রধান প্রধান প্রধান প্রধান প্রধান প্রধান প্রধান প্রধান প্রধান প্রধান প্রধান প্রধান প্রধান প্রধান প্রধান প্রধান প্রধান প্রধান প্রধান প্রধান প্রধান প্রধান প্রধান প্রধান প্রধান প্রধান প্রধান প্রধান প্রধান প্রধান প্রধান প্রধান প্রধান প্রধান প্রধান প্রধান প্রধান প্রধান প্রধান প্রধান প্রধান প্রধান প্রধান প্রধান প\n"
     ]
    }
   ],
   "source": [
    "# 4. Qwen Model Setup\n",
    "print(\"Loading Qwen3-0.6B model...\")\n",
    "model_name = \"Qwen/Qwen3-0.6B\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float16 if device == \"cuda\" else torch.float32,\n",
    "    device_map=\"auto\" if device == \"cuda\" else None,\n",
    "    low_cpu_mem_usage=True\n",
    ")\n",
    "\n",
    "# Create generation pipeline\n",
    "qwen_pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=500,\n",
    "    temperature=0.4,\n",
    "    top_p=0.9,\n",
    "    device=0 if device == \"cuda\" else -1\n",
    ")\n",
    "\n",
    "# LangChain wrapper\n",
    "llm = HuggingFacePipeline(pipeline=qwen_pipeline)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a071cac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain==0.1.14\n",
      "  Downloading langchain-0.1.14-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from langchain==0.1.14) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from langchain==0.1.14) (2.0.41)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from langchain==0.1.14) (3.12.14)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from langchain==0.1.14) (4.0.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from langchain==0.1.14) (0.6.7)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from langchain==0.1.14) (1.33)\n",
      "Collecting langchain-community<0.1,>=0.0.30 (from langchain==0.1.14)\n",
      "  Downloading langchain_community-0.0.38-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting langchain-core<0.2.0,>=0.1.37 (from langchain==0.1.14)\n",
      "  Downloading langchain_core-0.1.53-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langchain-text-splitters<0.1,>=0.0.1 (from langchain==0.1.14)\n",
      "  Downloading langchain_text_splitters-0.0.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain==0.1.14)\n",
      "  Downloading langsmith-0.1.147-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting numpy<2,>=1 (from langchain==0.1.14)\n",
      "  Downloading numpy-1.26.4-cp310-cp310-win_amd64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1 in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from langchain==0.1.14) (2.11.7)\n",
      "Requirement already satisfied: requests<3,>=2 in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from langchain==0.1.14) (2.32.4)\n",
      "Collecting tenacity<9.0.0,>=8.1.0 (from langchain==0.1.14)\n",
      "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.14) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.14) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.14) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.14) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.14) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.14) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.14) (1.20.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.14) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.14) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain==0.1.14) (3.0.0)\n",
      "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.37->langchain==0.1.14)\n",
      "  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.1.14) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.1.14) (3.11.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.1.14) (1.0.0)\n",
      "Requirement already satisfied: anyio in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.14) (4.9.0)\n",
      "Requirement already satisfied: certifi in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.14) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.14) (1.0.9)\n",
      "Requirement already satisfied: idna in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.14) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.14) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from multidict<7.0,>=4.5->aiohttp<4.0.0,>=3.8.3->langchain==0.1.14) (4.14.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from pydantic<3,>=1->langchain==0.1.14) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from pydantic<3,>=1->langchain==0.1.14) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from pydantic<3,>=1->langchain==0.1.14) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from requests<3,>=2->langchain==0.1.14) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from requests<3,>=2->langchain==0.1.14) (2.5.0)\n",
      "Requirement already satisfied: greenlet>=1 in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain==0.1.14) (3.2.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.1.14) (1.1.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.14) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.14) (1.3.1)\n",
      "Downloading langchain-0.1.14-py3-none-any.whl (812 kB)\n",
      "   ---------------------------------------- 0.0/812.8 kB ? eta -:--:--\n",
      "   ------------ --------------------------- 262.1/812.8 kB ? eta -:--:--\n",
      "   ------------ --------------------------- 262.1/812.8 kB ? eta -:--:--\n",
      "   ------------ --------------------------- 262.1/812.8 kB ? eta -:--:--\n",
      "   ------------------------ ------------- 524.3/812.8 kB 429.7 kB/s eta 0:00:01\n",
      "   ------------------------ ------------- 524.3/812.8 kB 429.7 kB/s eta 0:00:01\n",
      "   ------------------------ ------------- 524.3/812.8 kB 429.7 kB/s eta 0:00:01\n",
      "   -------------------------------------- 812.8/812.8 kB 451.7 kB/s eta 0:00:00\n",
      "Downloading langchain_community-0.0.38-py3-none-any.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/2.0 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.5/2.0 MB 1.7 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 0.5/2.0 MB 1.7 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 0.8/2.0 MB 985.5 kB/s eta 0:00:02\n",
      "   --------------- ------------------------ 0.8/2.0 MB 985.5 kB/s eta 0:00:02\n",
      "   --------------- ------------------------ 0.8/2.0 MB 985.5 kB/s eta 0:00:02\n",
      "   --------------- ------------------------ 0.8/2.0 MB 985.5 kB/s eta 0:00:02\n",
      "   --------------- ------------------------ 0.8/2.0 MB 985.5 kB/s eta 0:00:02\n",
      "   --------------- ------------------------ 0.8/2.0 MB 985.5 kB/s eta 0:00:02\n",
      "   --------------- ------------------------ 0.8/2.0 MB 985.5 kB/s eta 0:00:02\n",
      "   --------------- ------------------------ 0.8/2.0 MB 985.5 kB/s eta 0:00:02\n",
      "   --------------- ------------------------ 0.8/2.0 MB 985.5 kB/s eta 0:00:02\n",
      "   --------------- ------------------------ 0.8/2.0 MB 985.5 kB/s eta 0:00:02\n",
      "   -------------------- ------------------- 1.0/2.0 MB 306.8 kB/s eta 0:00:04\n",
      "   -------------------- ------------------- 1.0/2.0 MB 306.8 kB/s eta 0:00:04\n",
      "   -------------------- ------------------- 1.0/2.0 MB 306.8 kB/s eta 0:00:04\n",
      "   -------------------- ------------------- 1.0/2.0 MB 306.8 kB/s eta 0:00:04\n",
      "   ------------------------- -------------- 1.3/2.0 MB 309.2 kB/s eta 0:00:03\n",
      "   ------------------------- -------------- 1.3/2.0 MB 309.2 kB/s eta 0:00:03\n",
      "   ------------------------------- -------- 1.6/2.0 MB 336.9 kB/s eta 0:00:02\n",
      "   ------------------------------- -------- 1.6/2.0 MB 336.9 kB/s eta 0:00:02\n",
      "   ------------------------------------ --- 1.8/2.0 MB 364.7 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.8/2.0 MB 364.7 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 384.4 kB/s eta 0:00:00\n",
      "Downloading langchain_core-0.1.53-py3-none-any.whl (303 kB)\n",
      "Downloading langchain_text_splitters-0.0.2-py3-none-any.whl (23 kB)\n",
      "Downloading langsmith-0.1.147-py3-none-any.whl (311 kB)\n",
      "Downloading numpy-1.26.4-cp310-cp310-win_amd64.whl (15.8 MB)\n",
      "   ---------------------------------------- 0.0/15.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/15.8 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/15.8 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/15.8 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/15.8 MB 799.2 kB/s eta 0:00:20\n",
      "   - -------------------------------------- 0.5/15.8 MB 799.2 kB/s eta 0:00:20\n",
      "   - -------------------------------------- 0.8/15.8 MB 745.8 kB/s eta 0:00:21\n",
      "   - -------------------------------------- 0.8/15.8 MB 745.8 kB/s eta 0:00:21\n",
      "   - -------------------------------------- 0.8/15.8 MB 745.8 kB/s eta 0:00:21\n",
      "   - -------------------------------------- 0.8/15.8 MB 745.8 kB/s eta 0:00:21\n",
      "   - -------------------------------------- 0.8/15.8 MB 745.8 kB/s eta 0:00:21\n",
      "   - -------------------------------------- 0.8/15.8 MB 745.8 kB/s eta 0:00:21\n",
      "   -- ------------------------------------- 1.0/15.8 MB 375.7 kB/s eta 0:00:40\n",
      "   -- ------------------------------------- 1.0/15.8 MB 375.7 kB/s eta 0:00:40\n",
      "   -- ------------------------------------- 1.0/15.8 MB 375.7 kB/s eta 0:00:40\n",
      "   -- ------------------------------------- 1.0/15.8 MB 375.7 kB/s eta 0:00:40\n",
      "   --- ------------------------------------ 1.3/15.8 MB 372.9 kB/s eta 0:00:39\n",
      "   --- ------------------------------------ 1.3/15.8 MB 372.9 kB/s eta 0:00:39\n",
      "   --- ------------------------------------ 1.6/15.8 MB 397.5 kB/s eta 0:00:36\n",
      "   --- ------------------------------------ 1.6/15.8 MB 397.5 kB/s eta 0:00:36\n",
      "   --- ------------------------------------ 1.6/15.8 MB 397.5 kB/s eta 0:00:36\n",
      "   --- ------------------------------------ 1.6/15.8 MB 397.5 kB/s eta 0:00:36\n",
      "   ---- ----------------------------------- 1.8/15.8 MB 388.6 kB/s eta 0:00:36\n",
      "   ---- ----------------------------------- 1.8/15.8 MB 388.6 kB/s eta 0:00:36\n",
      "   ----- ---------------------------------- 2.1/15.8 MB 400.8 kB/s eta 0:00:35\n",
      "   ----- ---------------------------------- 2.1/15.8 MB 400.8 kB/s eta 0:00:35\n",
      "   ----- ---------------------------------- 2.1/15.8 MB 400.8 kB/s eta 0:00:35\n",
      "   ----- ---------------------------------- 2.4/15.8 MB 403.1 kB/s eta 0:00:34\n",
      "   ----- ---------------------------------- 2.4/15.8 MB 403.1 kB/s eta 0:00:34\n",
      "   ----- ---------------------------------- 2.4/15.8 MB 403.1 kB/s eta 0:00:34\n",
      "   ----- ---------------------------------- 2.4/15.8 MB 403.1 kB/s eta 0:00:34\n",
      "   ------ --------------------------------- 2.6/15.8 MB 404.8 kB/s eta 0:00:33\n",
      "   ------ --------------------------------- 2.6/15.8 MB 404.8 kB/s eta 0:00:33\n",
      "   ------- -------------------------------- 2.9/15.8 MB 415.3 kB/s eta 0:00:32\n",
      "   ------- -------------------------------- 2.9/15.8 MB 415.3 kB/s eta 0:00:32\n",
      "   ------- -------------------------------- 3.1/15.8 MB 422.3 kB/s eta 0:00:30\n",
      "   ------- -------------------------------- 3.1/15.8 MB 422.3 kB/s eta 0:00:30\n",
      "   ------- -------------------------------- 3.1/15.8 MB 422.3 kB/s eta 0:00:30\n",
      "   -------- ------------------------------- 3.4/15.8 MB 430.2 kB/s eta 0:00:29\n",
      "   -------- ------------------------------- 3.4/15.8 MB 430.2 kB/s eta 0:00:29\n",
      "   --------- ------------------------------ 3.7/15.8 MB 435.3 kB/s eta 0:00:28\n",
      "   --------- ------------------------------ 3.7/15.8 MB 435.3 kB/s eta 0:00:28\n",
      "   --------- ------------------------------ 3.9/15.8 MB 443.2 kB/s eta 0:00:27\n",
      "   --------- ------------------------------ 3.9/15.8 MB 443.2 kB/s eta 0:00:27\n",
      "   ---------- ----------------------------- 4.2/15.8 MB 454.3 kB/s eta 0:00:26\n",
      "   ---------- ----------------------------- 4.2/15.8 MB 454.3 kB/s eta 0:00:26\n",
      "   ----------- ---------------------------- 4.5/15.8 MB 462.0 kB/s eta 0:00:25\n",
      "   ----------- ---------------------------- 4.5/15.8 MB 462.0 kB/s eta 0:00:25\n",
      "   ----------- ---------------------------- 4.5/15.8 MB 462.0 kB/s eta 0:00:25\n",
      "   ----------- ---------------------------- 4.7/15.8 MB 460.8 kB/s eta 0:00:25\n",
      "   ----------- ---------------------------- 4.7/15.8 MB 460.8 kB/s eta 0:00:25\n",
      "   ------------ --------------------------- 5.0/15.8 MB 463.9 kB/s eta 0:00:24\n",
      "   ------------ --------------------------- 5.0/15.8 MB 463.9 kB/s eta 0:00:24\n",
      "   ------------ --------------------------- 5.0/15.8 MB 463.9 kB/s eta 0:00:24\n",
      "   ------------ --------------------------- 5.0/15.8 MB 463.9 kB/s eta 0:00:24\n",
      "   ------------- -------------------------- 5.2/15.8 MB 454.7 kB/s eta 0:00:24\n",
      "   ------------- -------------------------- 5.2/15.8 MB 454.7 kB/s eta 0:00:24\n",
      "   ------------- -------------------------- 5.2/15.8 MB 454.7 kB/s eta 0:00:24\n",
      "   ------------- -------------------------- 5.2/15.8 MB 454.7 kB/s eta 0:00:24\n",
      "   ------------- -------------------------- 5.2/15.8 MB 454.7 kB/s eta 0:00:24\n",
      "   ------------- -------------------------- 5.5/15.8 MB 442.1 kB/s eta 0:00:24\n",
      "   ------------- -------------------------- 5.5/15.8 MB 442.1 kB/s eta 0:00:24\n",
      "   ------------- -------------------------- 5.5/15.8 MB 442.1 kB/s eta 0:00:24\n",
      "   ------------- -------------------------- 5.5/15.8 MB 442.1 kB/s eta 0:00:24\n",
      "   ------------- -------------------------- 5.5/15.8 MB 442.1 kB/s eta 0:00:24\n",
      "   -------------- ------------------------- 5.8/15.8 MB 426.0 kB/s eta 0:00:24\n",
      "   -------------- ------------------------- 5.8/15.8 MB 426.0 kB/s eta 0:00:24\n",
      "   -------------- ------------------------- 5.8/15.8 MB 426.0 kB/s eta 0:00:24\n",
      "   --------------- ------------------------ 6.0/15.8 MB 422.3 kB/s eta 0:00:24\n",
      "   --------------- ------------------------ 6.0/15.8 MB 422.3 kB/s eta 0:00:24\n",
      "   --------------- ------------------------ 6.0/15.8 MB 422.3 kB/s eta 0:00:24\n",
      "   --------------- ------------------------ 6.3/15.8 MB 425.0 kB/s eta 0:00:23\n",
      "   --------------- ------------------------ 6.3/15.8 MB 425.0 kB/s eta 0:00:23\n",
      "   ---------------- ----------------------- 6.6/15.8 MB 428.8 kB/s eta 0:00:22\n",
      "   ---------------- ----------------------- 6.6/15.8 MB 428.8 kB/s eta 0:00:22\n",
      "   ----------------- ---------------------- 6.8/15.8 MB 436.0 kB/s eta 0:00:21\n",
      "   ----------------- ---------------------- 7.1/15.8 MB 444.2 kB/s eta 0:00:20\n",
      "   ----------------- ---------------------- 7.1/15.8 MB 444.2 kB/s eta 0:00:20\n",
      "   ------------------ --------------------- 7.3/15.8 MB 453.0 kB/s eta 0:00:19\n",
      "   ------------------- -------------------- 7.6/15.8 MB 461.9 kB/s eta 0:00:18\n",
      "   ------------------- -------------------- 7.9/15.8 MB 471.5 kB/s eta 0:00:17\n",
      "   -------------------- ------------------- 8.1/15.8 MB 480.7 kB/s eta 0:00:16\n",
      "   --------------------- ------------------ 8.4/15.8 MB 490.2 kB/s eta 0:00:16\n",
      "   --------------------- ------------------ 8.7/15.8 MB 499.9 kB/s eta 0:00:15\n",
      "   ---------------------- ----------------- 8.9/15.8 MB 509.3 kB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 8.9/15.8 MB 509.3 kB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 9.2/15.8 MB 516.7 kB/s eta 0:00:13\n",
      "   ----------------------- ---------------- 9.4/15.8 MB 524.3 kB/s eta 0:00:13\n",
      "   ------------------------ --------------- 9.7/15.8 MB 529.8 kB/s eta 0:00:12\n",
      "   ------------------------ --------------- 9.7/15.8 MB 529.8 kB/s eta 0:00:12\n",
      "   ------------------------- -------------- 10.0/15.8 MB 535.6 kB/s eta 0:00:11\n",
      "   ------------------------- -------------- 10.0/15.8 MB 535.6 kB/s eta 0:00:11\n",
      "   ------------------------- -------------- 10.0/15.8 MB 535.6 kB/s eta 0:00:11\n",
      "   ------------------------- -------------- 10.2/15.8 MB 527.8 kB/s eta 0:00:11\n",
      "   ------------------------- -------------- 10.2/15.8 MB 527.8 kB/s eta 0:00:11\n",
      "   ------------------------- -------------- 10.2/15.8 MB 527.8 kB/s eta 0:00:11\n",
      "   ------------------------- -------------- 10.2/15.8 MB 527.8 kB/s eta 0:00:11\n",
      "   -------------------------- ------------- 10.5/15.8 MB 520.9 kB/s eta 0:00:11\n",
      "   -------------------------- ------------- 10.5/15.8 MB 520.9 kB/s eta 0:00:11\n",
      "   --------------------------- ------------ 10.7/15.8 MB 521.0 kB/s eta 0:00:10\n",
      "   --------------------------- ------------ 10.7/15.8 MB 521.0 kB/s eta 0:00:10\n",
      "   --------------------------- ------------ 10.7/15.8 MB 521.0 kB/s eta 0:00:10\n",
      "   --------------------------- ------------ 11.0/15.8 MB 519.9 kB/s eta 0:00:10\n",
      "   --------------------------- ------------ 11.0/15.8 MB 519.9 kB/s eta 0:00:10\n",
      "   --------------------------- ------------ 11.0/15.8 MB 519.9 kB/s eta 0:00:10\n",
      "   ---------------------------- ----------- 11.3/15.8 MB 516.6 kB/s eta 0:00:09\n",
      "   ---------------------------- ----------- 11.3/15.8 MB 516.6 kB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 11.5/15.8 MB 517.9 kB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 11.5/15.8 MB 517.9 kB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 11.8/15.8 MB 520.6 kB/s eta 0:00:08\n",
      "   ----------------------------- ---------- 11.8/15.8 MB 520.6 kB/s eta 0:00:08\n",
      "   ------------------------------ --------- 12.1/15.8 MB 524.7 kB/s eta 0:00:08\n",
      "   ------------------------------- -------- 12.3/15.8 MB 529.3 kB/s eta 0:00:07\n",
      "   ------------------------------- -------- 12.3/15.8 MB 529.3 kB/s eta 0:00:07\n",
      "   ------------------------------- -------- 12.6/15.8 MB 534.2 kB/s eta 0:00:07\n",
      "   -------------------------------- ------- 12.8/15.8 MB 539.4 kB/s eta 0:00:06\n",
      "   --------------------------------- ------ 13.1/15.8 MB 545.2 kB/s eta 0:00:05\n",
      "   --------------------------------- ------ 13.4/15.8 MB 551.2 kB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 13.6/15.8 MB 557.1 kB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 13.9/15.8 MB 563.2 kB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 14.2/15.8 MB 569.3 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 14.4/15.8 MB 575.6 kB/s eta 0:00:03\n",
      "   ------------------------------------- -- 14.7/15.8 MB 581.8 kB/s eta 0:00:02\n",
      "   ------------------------------------- -- 14.9/15.8 MB 588.3 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 15.2/15.8 MB 593.6 kB/s eta 0:00:02\n",
      "   ---------------------------------------  15.5/15.8 MB 598.8 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.8/15.8 MB 605.6 kB/s eta 0:00:00\n",
      "Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
      "Downloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Installing collected packages: tenacity, packaging, numpy, langsmith, langchain-core, langchain-text-splitters, langchain-community, langchain\n",
      "\n",
      "  Attempting uninstall: tenacity\n",
      "\n",
      "    Found existing installation: tenacity 9.1.2\n",
      "\n",
      "    Uninstalling tenacity-9.1.2:\n",
      "\n",
      "      Successfully uninstalled tenacity-9.1.2\n",
      "\n",
      "  Attempting uninstall: packaging\n",
      "\n",
      "    Found existing installation: packaging 24.2\n",
      "\n",
      "    Uninstalling packaging-24.2:\n",
      "\n",
      "      Successfully uninstalled packaging-24.2\n",
      "\n",
      "  Attempting uninstall: numpy\n",
      "\n",
      "    Found existing installation: numpy 2.2.6\n",
      "\n",
      "   ---------- ----------------------------- 2/8 [numpy]\n",
      "   ---------- ----------------------------- 2/8 [numpy]\n",
      "    Uninstalling numpy-2.2.6:\n",
      "   ---------- ----------------------------- 2/8 [numpy]\n",
      "   ---------- ----------------------------- 2/8 [numpy]\n",
      "   ---------- ----------------------------- 2/8 [numpy]\n",
      "   ---------- ----------------------------- 2/8 [numpy]\n",
      "   ---------- ----------------------------- 2/8 [numpy]\n",
      "   ---------- ----------------------------- 2/8 [numpy]\n",
      "   ---------- ----------------------------- 2/8 [numpy]\n",
      "   ---------- ----------------------------- 2/8 [numpy]\n",
      "   ---------- ----------------------------- 2/8 [numpy]\n",
      "   ---------- ----------------------------- 2/8 [numpy]\n",
      "   ---------- ----------------------------- 2/8 [numpy]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -egex (e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -egex (e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages)\n",
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'e:\\\\data\\\\new folder\\\\envs\\\\hscbookbot\\\\lib\\\\site-packages\\\\numpy.libs\\\\libscipy_openblas64_-13e2df515630b4a41f92893938845698.dll'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!\"{sys.executable}\" -m pip install langchain==0.1.14\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "91f96122",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fb719507",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "9c7f2120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building RAG chain...\n",
      "\n",
      "System ready. Testing with sample query...\n",
      "ANSWER: Nelson Mandela was a South African leader who fought for the liberation of the people from apartheid and became a symbol of peace and reconciliation. He was awarded the Nobel Peace Prize in 1993.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 5. RAG Setup\n",
    "print(\"Building RAG chain...\")\n",
    "system_prompt = \"\"\"Answer questions using the provided context in the same language as the question. \n",
    "Follow these rules strictly:\n",
    "\n",
    "1. Language Handling:\n",
    "- Detect the question's language automatically\n",
    "- Respond in the same language as the question\n",
    "- For Bangla queries, respond in authentic Bangla (not transliterated)\n",
    "\n",
    "2. Answer Generation:\n",
    "- Use only the provided context to answer\n",
    "- If the answer isn't in the context, say:\n",
    "  - English: \"I don't have information about this.\"\n",
    "  - Bangla: \"আমার কাছে এই সম্পর্কে কোনো তথ্য নেই।\"\n",
    "- Keep answers concise (2-3 sentences)\n",
    "- For Bangla answers, please give in 1 to 2 sentences\n",
    "\n",
    "3. Context Usage:\n",
    "- Prioritize information from the retrieved context\n",
    "- Never make up facts not present in the context\n",
    "- Combine information from multiple chunks when needed\n",
    "4.Do not include this prompt in the answer and read the extracted contexts very carefully. \n",
    "please do not include system prompt in the answer as weel as the retrieved context. only start the answer by Saying \"ANSWER:\".\n",
    "\n",
    "If you don't know, say so. Keep answers concise (1-2 sentences).Context:\n",
    "{context}\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt + \"\\nContext: {context}\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "])\n",
    "\n",
    "rag_chain = create_retrieval_chain(\n",
    "    retriever,\n",
    "    create_stuff_documents_chain(llm, prompt)\n",
    ")\n",
    "\n",
    "import re\n",
    "\n",
    "print(\"\\nSystem ready. Testing with sample query...\")\n",
    "query = \"Who is Nelson Mandela?\"\n",
    "\n",
    "try:\n",
    "    response = rag_chain.invoke({\"input\": query})\n",
    "    full_answer = response[\"answer\"]\n",
    "\n",
    "    matches = re.findall(r\"(?i)^ANSWER:\\s*(.+)\", full_answer, re.MULTILINE)\n",
    "\n",
    "    if matches:\n",
    "        print(f\"{matches[0]}\")\n",
    "    else:\n",
    "        print(\"No valid answer found.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "03b29a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Who is Nelson Mandela?\n",
      "Answer: System: You are a bilingual assistant that answers questions in both English and Bangla.\n"
     ]
    }
   ],
   "source": [
    "# 3. Add this response cleaner function\n",
    "def get_clean_answer(response):\n",
    "    \"\"\"Extracts only the pure answer text\"\"\"\n",
    "    answer = response['answer']\n",
    "    # Remove any context references\n",
    "    if \"Context:\" in answer:\n",
    "        answer = answer.split(\"Context:\")[0]\n",
    "    # Take only the first sentence if multiple exist\n",
    "    return answer.split(\".\")[0] + \".\" if \".\" in answer else answer\n",
    "\n",
    "# 4. Test it\n",
    "query = \"Who is Nelson Mandela?\"\n",
    "response = rag_chain.invoke({\"input\": query})\n",
    "clean_answer = get_clean_answer(response)\n",
    "\n",
    "print(f\"Question: {query}\")\n",
    "print(f\"Answer: {clean_answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c157ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Who is Nelson Mandela?\n",
      "Answer: System: Answer the question in the same language as asked using ONLY the context below. \n",
      "     Respond with JUST THE ANSWER in 1-2 sentences. No prefixes, no explanations.\n",
      "     \n",
      "     Context: together with others has ................... his humble contribution.” \n",
      "[The text on Mandela is written by Andrew Quinn and Jon Herskovitz; Edited by Pascal Fletcher and \n",
      "Angus MacSwan. Source: http://tv.yahoo.com/news/nelson-mandela-apartheid-fighter-president-unifier- \n",
      "105117261.html, accessed on 14/02/2014] \n",
      "2022-2023\n",
      "\n",
      "Imprisoned for nearly three decades for his fight against white minority rule, 5 \n",
      "Mandela never lost his resolve to fight for is people's emancipation. He was \n",
      "determined to bring down apartheid while avoiding a civil war. His prestige and \n",
      "charigma helped him win the support of the world. \n",
      "2022-2023\n",
      "\n",
      "In 1993, Mandela was awarded the Nobel Peace Prize, an honor he shared with \n",
      "F.W. de Klerk, the white South African leader who had freed him from prison three \n",
      "years earlier and negotiated the end of apartheid. \n",
      "Mandela went on to play a prominent role on the world stage as an advocate of \n",
      "human dignity in the face of challenges ranging from political repression to AIDS. \n",
      "He formally left public life in June 2004 before his 86th birthday, telling his\n",
      "\n",
      "“If cancer wins I will still ........ the better winner,” he told reporters in ........ of \n",
      "that year. “When I go ........ the next world, the first thing I will .............. is look \n",
      "for an ANC offfice to ................0008 my membership.” \n",
      "Most South Africans are proud ..... their post-apartheid multi-racial 'Rainbow Nation’. \n",
      "H. Now fill in the gaps in the text below using suitable words. \n",
      "Mandela’s last major appearance on the .......... stage was in 2010 when he ..........\n",
      "\n",
      "English For Today \n",
      "Lesson 2 \n",
      "Nelson Mandela, from Apartheid Fighter te President \n",
      "ems rr, \n",
      "hy \n",
      "A. Warm up activity: \n",
      "Work in pairs. \n",
      "O) Who do you see in picture? What do you know about him? \n",
      "B. Read the text. \n",
      "15 December 2013 \n",
      "JOHANNESBURG (Reuters)—Nelson Mandela guided South Affica from the \n",
      "shackles of apartheid to a multi-racial democracy, as an icon of peace and \n",
      "reconciliation who came to embody the struggle for justice around the world.\n",
      "Human: Who is Nelson Mandela? \n",
      "Answer: \n",
      "\n",
      "The answer should be in English. \n",
      "\n",
      "Answer:\n",
      "The answer should be in English. \n",
      "\n",
      "Answer:\n",
      "The answer should be in English. \n",
      "\n",
      "Answer:\n",
      "The answer should be in English. \n",
      "\n",
      "Answer:\n",
      "The answer should be in English. \n",
      "\n",
      "Answer:\n",
      "The answer should be in English. \n",
      "\n",
      "Answer:\n",
      "The answer should be in English. \n",
      "\n",
      "Answer:\n",
      "The answer should be in English. \n",
      "\n",
      "Answer:\n",
      "The answer should be in English. \n",
      "\n",
      "Answer:\n",
      "The answer should be in English. \n",
      "\n",
      "Answer:\n",
      "The answer should be in English. \n",
      "\n",
      "Answer:\n",
      "The answer should be in English. \n",
      "\n",
      "Answer:\n",
      "The answer should be in English. \n",
      "\n",
      "Answer:\n",
      "The answer should be in English. \n",
      "\n",
      "Answer:\n",
      "The answer should be in English. \n",
      "\n",
      "Answer:\n",
      "The answer should be in English. \n",
      "\n",
      "Answer:\n",
      "The answer should be in English. \n",
      "\n",
      "Answer:\n",
      "The answer should be in English. \n",
      "\n",
      "Answer:\n",
      "The answer should be in English. \n",
      "\n",
      "Answer:\n",
      "The answer should be in English. \n",
      "\n",
      "Answer:\n",
      "The answer should be in English. \n",
      "\n",
      "Answer:\n",
      "The answer should be in English. \n",
      "\n",
      "Answer:\n",
      "The answer should be in English. \n",
      "\n",
      "Answer:\n",
      "The answer should be in English. \n",
      "\n",
      "Answer:\n",
      "The answer should be in English. \n",
      "\n",
      "Answer:\n",
      "The answer should be in English. \n",
      "\n",
      "Answer:\n",
      "The answer should be in English. \n",
      "\n",
      "Answer:\n",
      "The answer should be in English. \n",
      "\n",
      "Answer:\n",
      "The answer should be in English. \n",
      "\n",
      "Answer:\n",
      "The answer should be in English. \n",
      "\n",
      "Answer:\n",
      "The answer should be in English. \n",
      "\n",
      "Answer:\n",
      "The answer should be in English. \n",
      "\n",
      "Answer:\n",
      "The answer should be in English. \n",
      "\n",
      "Answer:\n",
      "The answer should be in English. \n",
      "\n",
      "Answer:\n",
      "The answer should be in English. \n",
      "\n",
      "Answer:\n",
      "The answer should be in English. \n",
      "\n",
      "Answer:\n",
      "The answer should be in English. \n",
      "\n",
      "Answer:\n",
      "The answer should be in English. \n",
      "\n",
      "Answer:\n",
      "The answer should be in English. \n",
      "\n",
      "Answer:\n",
      "The answer should be in English. \n",
      "\n",
      "Answer:\n",
      "The answer should be in English. \n",
      "\n",
      "Answer:\n",
      "The answer should be in English. \n",
      "\n",
      "Answer:\n",
      "The answer should be in English. \n",
      "\n",
      "Answer:\n",
      "The answer should be in English. \n",
      "\n",
      "Answer:\n",
      "The answer should be in English. \n",
      "\n",
      "Answer:\n",
      "The answer should be in English. \n",
      "\n",
      "Answer:\n",
      "The answer should be in English. \n",
      "\n",
      "Answer:\n",
      "The answer should be in English. \n",
      "\n",
      "Answer:\n",
      "The answer should be in English. \n",
      "\n",
      "Answer:\n",
      "The answer should be in English\n"
     ]
    }
   ],
   "source": [
    "# 1. Use this EXACT prompt template\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"Answer the question in the same language as asked using ONLY the context below. \n",
    "     Respond with JUST THE ANSWER in 1-2 sentences. No prefixes, no explanations.\n",
    "     \n",
    "     Context: {context}\"\"\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "])\n",
    "\n",
    "# 2. Create the chain\n",
    "rag_chain = create_retrieval_chain(\n",
    "    retriever,\n",
    "    create_stuff_documents_chain(llm, prompt)\n",
    ")\n",
    "\n",
    "# 3. Use this extraction function\n",
    "def get_clean_answer(response):\n",
    "    \"\"\"Returns ONLY the answer text\"\"\"\n",
    "    return response['answer'].strip()\n",
    "\n",
    "# 4. Test it\n",
    "query = \"Who is Nelson Mandela?\"\n",
    "response = rag_chain.invoke({\"input\": query})\n",
    "answer = get_clean_answer(response)\n",
    "\n",
    "\n",
    "print(f\"Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c0ae1dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "System ready. Testing with sample query...\n",
      "\n",
      "Question: Who is Nelson Mandela?\n",
      "Answer: System: You are a bilingual assistant that answers questions in both English and Bangla. \n",
      "Follow these rules strictly:\n",
      "\n",
      "1. Use the following context to answer the question:\n",
      "together with others has ................... his humble contribution.” \n",
      "[The text on Mandela is written by Andrew Quinn and Jon Herskovitz; Edited by Pascal Fletcher and \n",
      "Angus MacSwan. Source: http://tv.yahoo.com/news/nelson-mandela-apartheid-fighter-president-unifier- \n",
      "105117261.html, accessed on 14/02/2014] \n",
      "2022-2023\n",
      "\n",
      "Imprisoned for nearly three decades for his fight against white minority rule, 5 \n",
      "Mandela never lost his resolve to fight for is people's emancipation. He was \n",
      "determined to bring down apartheid while avoiding a civil war. His prestige and \n",
      "charigma helped him win the support of the world. \n",
      "2022-2023\n",
      "\n",
      "In 1993, Mandela was awarded the Nobel Peace Prize, an honor he shared with \n",
      "F.W. de Klerk, the white South African leader who had freed him from prison three \n",
      "years earlier and negotiated the end of apartheid. \n",
      "Mandela went on to play a prominent role on the world stage as an advocate of \n",
      "human dignity in the face of challenges ranging from political repression to AIDS. \n",
      "He formally left public life in June 2004 before his 86th birthday, telling his\n",
      "\n",
      "“If cancer wins I will still ........ the better winner,” he told reporters in ........ of \n",
      "that year. “When I go ........ the next world, the first thing I will .............. is look \n",
      "for an ANC offfice to ................0008 my membership.” \n",
      "Most South Africans are proud ..... their post-apartheid multi-racial 'Rainbow Nation’. \n",
      "H. Now fill in the gaps in the text below using suitable words. \n",
      "Mandela’s last major appearance on the .......... stage was in 2010 when he ..........\n",
      "\n",
      "English For Today \n",
      "Lesson 2 \n",
      "Nelson Mandela, from Apartheid Fighter te President \n",
      "ems rr, \n",
      "hy \n",
      "A. Warm up activity: \n",
      "Work in pairs. \n",
      "O) Who do you see in picture? What do you know about him? \n",
      "B. Read the text. \n",
      "15 December 2013 \n",
      "JOHANNESBURG (Reuters)—Nelson Mandela guided South Affica from the \n",
      "shackles of apartheid to a multi-racial democracy, as an icon of peace and \n",
      "reconciliation who came to embody the struggle for justice around the world.\n",
      "\n",
      "2. Language Handling:\n",
      "- Detect the question's language automatically\n",
      "- Respond in the same language as the question\n",
      "- For Bangla queries, respond in authentic Bangla (not transliterated)\n",
      "\n",
      "3. If the answer isn't in the context, say:\n",
      "- English: \"I don't have information about this.\"\n",
      "- Bangla: \"আমার কাছে এই সম্পর্কে কোনো তথ্য নেই।\"\n",
      "\n",
      "Human: Who is Nelson Mandela? \n",
      "\n",
      "Assistant: (Bangla) \"Nelson Mandela is a prominent figure in South Africa. He was a leader who fought against apartheid and worked to bring about a more peaceful and democratic society.\" \n",
      "\n",
      "Answer:\n",
      "(English) \"Nelson Mandela is a prominent figure in South Africa. He was a leader who fought against apartheid and worked to bring about a more peaceful and democratic society.\"\n",
      "\n",
      "Answer:\n",
      "(English) \"Nelson Mandela is a prominent figure in South Africa. He was a leader who fought against apartheid and worked to bring about a more peaceful and democratic society.\"\n",
      "\n",
      "Answer:\n",
      "(English) \"Nelson Mandela is a prominent figure in South Africa. He was a leader who fought against apartheid and worked to bring about a more peaceful and democratic society.\"\n",
      "\n",
      "Answer:\n",
      "(English) \"Nelson Mandela is a prominent figure in South Africa. He was a leader who fought against apartheid and worked to bring about a more peaceful and democratic society.\"\n",
      "\n",
      "Answer:\n",
      "(English) \"Nelson Mandela is a prominent figure in South Africa. He was a leader who fought against apartheid and worked to bring about a more peaceful and democratic society.\"\n",
      "\n",
      "Answer:\n",
      "(English) \"Nelson Mandela is a prominent figure in South Africa. He was a leader who fought against apartheid and worked to bring about a more peaceful and democratic society.\"\n",
      "\n",
      "Answer:\n",
      "(English) \"Nelson Mandela is a prominent figure in South Africa. He was a leader who fought against apartheid and worked to bring about a more peaceful and democratic society.\"\n",
      "\n",
      "Answer:\n",
      "(English) \"Nelson Mandela is a prominent figure in South Africa. He was a leader who fought against apartheid and worked to bring about a more peaceful and democratic society.\"\n",
      "\n",
      "Answer:\n",
      "(English) \"Nelson Mandela is a prominent figure in South Africa. He was a leader who fought against apartheid and worked to bring about a more peaceful and democratic society.\"\n",
      "\n",
      "Answer:\n",
      "(English) \"Nelson Mandela is a prominent figure in South Africa. He was a leader who fought against apartheid and worked to bring about a more peaceful and democratic society.\"\n",
      "\n",
      "Answer:\n",
      "(English) \"Nelson Mandela is a prominent figure in South Africa. He was a leader who fought against apartheid and worked to bring about a more peaceful and democratic society.\"\n",
      "\n",
      "Answer:\n",
      "(English) \"Nelson Mandela is a prominent figure in South Africa. He was a leader who fought against apartheid and worked to bring about a more peaceful and democratic society.\"\n",
      "\n",
      "Answer:\n",
      "(English) \"Nelson Mandela is a prominent figure in South Africa\n"
     ]
    }
   ],
   "source": [
    "# 6. Query Example\n",
    "print(\"\\nSystem ready. Testing with sample query...\")\n",
    "query = \"Who is Nelson Mandela?\"\n",
    "try:\n",
    "    response = rag_chain.invoke({\"input\": query})\n",
    "    print(f\"\\nQuestion: {query}\")\n",
    "    print(f\"Answer: {response['answer']}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5a6258ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: langchain\n",
      "Version: 0.3.26\n",
      "Summary: Building applications with LLMs through composability\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages\n",
      "Requires: async-timeout, langchain-core, langchain-text-splitters, langsmith, pydantic, PyYAML, requests, SQLAlchemy\n",
      "Required-by: langchain-community\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -egex (e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip show langchain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "09c8b9c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting deep-translator\n",
      "  Downloading deep_translator-1.11.4-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting beautifulsoup4<5.0.0,>=4.9.1 (from deep-translator)\n",
      "  Using cached beautifulsoup4-4.13.4-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.23.0 in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from deep-translator) (2.32.4)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4<5.0.0,>=4.9.1->deep-translator)\n",
      "  Using cached soupsieve-2.7-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep-translator) (4.14.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2025.7.14)\n",
      "Downloading deep_translator-1.11.4-py3-none-any.whl (42 kB)\n",
      "Using cached beautifulsoup4-4.13.4-py3-none-any.whl (187 kB)\n",
      "Using cached soupsieve-2.7-py3-none-any.whl (36 kB)\n",
      "Installing collected packages: soupsieve, beautifulsoup4, deep-translator\n",
      "\n",
      "   ------------- -------------------------- 1/3 [beautifulsoup4]\n",
      "   ---------------------------------------- 3/3 [deep-translator]\n",
      "\n",
      "Successfully installed beautifulsoup4-4.13.4 deep-translator-1.11.4 soupsieve-2.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -egex (e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -egex (e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -egex (e:\\data\\new folder\\envs\\hscbookbot\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install deep-translator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "943e3c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langdetect import detect\n",
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "# --- 1. Define the system prompt ---\n",
    "system_prompt = \"\"\"You are a bilingual assistant that answers questions in both English and Bangla. \n",
    "Follow these rules strictly:\n",
    "\n",
    "1. Language Handling:\n",
    "- Detect the question's language automatically\n",
    "- Respond in the same language as the question\n",
    "- For Bangla queries, respond in authentic Bangla (not transliterated)\n",
    "\n",
    "2. Answer Generation:\n",
    "- Use only the provided context to answer\n",
    "- If the answer isn't in the context, say:\n",
    "  - English: \"I don't have information about this.\"\n",
    "  - Bangla: \"আমার কাছে এই সম্পর্কে কোনো তথ্য নেই।\"\n",
    "- Keep answers concise (2-3 sentences)\n",
    "- For Bangla answers, please give in 1 to 3 words\n",
    "\n",
    "3. Context Usage:\n",
    "- Prioritize information from the retrieved context\n",
    "- Never make up facts not present in the context\n",
    "- Combine information from multiple chunks when needed\n",
    "\n",
    "Context:\n",
    "{context}\"\"\"\n",
    "\n",
    "# --- 2. Create the prompt template ---\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"human\", \"{input}\"),\n",
    "])\n",
    "\n",
    "# --- 3. Create the core RAG chain ---\n",
    "rag_chain = create_retrieval_chain(\n",
    "    retriever,\n",
    "    create_stuff_documents_chain(llm, prompt)\n",
    ")\n",
    "\n",
    "# --- 4. Language detection helpers ---\n",
    "def is_bangla(text):\n",
    "    try:\n",
    "        return detect(text) == 'bn'\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def translate_to_english(text):\n",
    "    try:\n",
    "        return GoogleTranslator(source='bn', target='en').translate(text)\n",
    "    except:\n",
    "        return text\n",
    "\n",
    "def translate_to_bangla(text):\n",
    "    try:\n",
    "        return GoogleTranslator(source='en', target='bn').translate(text)\n",
    "    except:\n",
    "        return text\n",
    "\n",
    "def ask_rag(query):\n",
    "    is_bn = is_bangla(query)\n",
    "\n",
    "    # 1. Retrieve Bangla documents\n",
    "    retrieved_docs = retriever.invoke(query)\n",
    "    original_context = \" \".join([doc.page_content for doc in retrieved_docs])\n",
    "\n",
    "    # 2. Translate context (Bangla ➝ English) if needed\n",
    "    context = translate_to_english(original_context) if is_bn else original_context\n",
    "\n",
    "    # 3. RAG prompt execution\n",
    "    response = rag_chain.invoke({\n",
    "        \"input\": query,\n",
    "        \"context\": context\n",
    "    })\n",
    "\n",
    "    # 4. Translate output (English ➝ Bangla) if needed\n",
    "    answer = response[\"answer\"]\n",
    "    if is_bn:\n",
    "        answer = translate_to_bangla(answer)\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9c932a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Bangla query: কাকে অনুপমের ভাগ্য দেবতা বলে উল্লেখ করা হয়েছে?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\data\\New folder\\envs\\HSCbookbot\\lib\\site-packages\\langchain_community\\vectorstores\\qdrant.py:610: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  results = self.client.search(\n",
      "e:\\data\\New folder\\envs\\HSCbookbot\\lib\\site-packages\\langchain_community\\vectorstores\\qdrant.py:610: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  results = self.client.search(\n",
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: সিস্টেম: আপনি দ্বিভাষিক সহকারী যা ইংরেজি এবং বাংলা উভয়ের প্রশ্নের উত্তর দেয়। \n",
      "এই নিয়মগুলি কঠোরভাবে অনুসরণ করুন:\n",
      "\n",
      "1। ভাষা পরিচালনা:\n",
      "- প্রশ্নের ভাষা স্বয়ংক্রিয়ভাবে সনাক্ত করুন\n",
      "- প্রশ্ন হিসাবে একই ভাষায় প্রতিক্রিয়া\n",
      "- বাংলা প্রশ্নের জন্য, খাঁটি বাংলায় সাড়া দিন (অনুবাদক নয়)\n",
      "\n",
      "2। উত্তর প্রজন্ম:\n",
      "- উত্তর দিতে কেবল প্রদত্ত প্রসঙ্গটি ব্যবহার করুন\n",
      "- যদি উত্তরটি প্রসঙ্গে না থাকে তবে বলুন:\n",
      "  - ইংরেজি: \"আমার কাছে এ সম্পর্কে তথ্য নেই।\"\n",
      "  - বাংলা: \"আমার আমার এই সম্পর্কে কোনো তথ্য নেই।\"\n",
      "- উত্তরগুলি সংক্ষিপ্ত রাখুন (২-৩ বাক্য)\n",
      "- বাংলা উত্তরের জন্য, দয়া করে 1 থেকে 3 টি শব্দ দিন\n",
      "\n",
      "3। প্রসঙ্গ ব্যবহার:\n",
      "- পুনরুদ্ধার প্রসঙ্গ থেকে তথ্য অগ্রাধিকার দিন\n",
      "- প্রসঙ্গে উপস্থিত নয় এমন ঘটনা কখনও আপ করবেন না\n",
      "- প্রয়োজনে একাধিক খণ্ড থেকে তথ্য একত্রিত করুন\n",
      "\n",
      "প্রসঙ্গ:\n",
      "মনের এমন বিক্ষিপ্ত অবস্থায় কী লেখা লেখা? যদি যায় তো সে কবিতা, প্রবন্ধ প্রবন্ধ \n",
      "২০২২-২০২৩\n",
      "\n",
      "করিবেন | তাহা হইলে দেখিবেন, প্রবন্ধে প্রবন্ধে অনেক আছে। আছে। কাব্য নাটক উপন্যাস দুই এক এক বৎসর ফেলিয়া\n",
      "\n",
      "কথামালা | অনুপমের আত্মবিবৃতির সূত্র ধরেই গল্পের নারী কল্যাণী কল্যাণী অসামান্যা হয়ে উঠেছে। গল্পটিতে \n",
      "হয়েছে। \n",
      "২০২২-২০২৩\n",
      "\n",
      "এত সার্ভিস দিচ্ছে, তার তার, তওবা, সাব-অর্ডিনেটের জন্যে এতটুকু এতটুকু করবে না?\n",
      "\n",
      "পানিতে বাসে সয়লাব হয়ে গেলেও কেউ টু টু শব্দটি করছে না? তার পোশাক কি সবাইকে ঘাবড়ে দিল দিল?\n",
      "মানব: কাকে অনুপমের ভাগ্য দেবতা বলে উল্লেখ করা হয়েছে? \n",
      "\n",
      "প্রসঙ্গ:\n",
      "মনের এমন বিক্ষিপ্ত অবস্থায় কী লেখা লেখা? যদি যায় তো সে কবিতা, প্রবন্ধ প্রবন্ধ \n",
      "২০২২-২০২৩\n",
      "\n",
      "করিবেন | তাহা হইলে দেখিবেন, প্রবন্ধে প্রবন্ধে অনেক আছে। আছে। কাব্য নাটক উপন্যাস দুই এক এক বৎসর ফেলিয়া\n",
      "\n",
      "কথামালা | অনুপমের আত্মবিবৃতির সূত্র ধরেই গল্পের নারী কল্যাণী কল্যাণী অসামান্যা হয়ে উঠেছে। গল্পটিতে \n",
      "\n",
      "২০২২-২০২৩\n",
      "\n",
      "এত সার্ভিস দিচ্ছে, তার কলিগের, ত�বা, সাব-অর্ডিনেটের জন্যে এতটুকু এতটুকু করবে না?\n",
      "\n",
      "পানিতে বাসে সয়লাব হয়ে গেলেও কেউ টু টু শব্দটি করছে না? তার পোশাক কি সবাইকে ঘাবড়ে দিল দিল?\n",
      "\n",
      "প্রসঙ্গ:\n",
      "মনের এমন বিক্ষিপ্�\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\data\\New folder\\envs\\HSCbookbot\\lib\\site-packages\\langchain_community\\vectorstores\\qdrant.py:610: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  results = self.client.search(\n",
      "e:\\data\\New folder\\envs\\HSCbookbot\\lib\\site-packages\\langchain_community\\vectorstores\\qdrant.py:610: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  results = self.client.search(\n",
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bangla Answer: সিস্টেম: আপনি দ্বিভাষিক সহকারী যা ইংরেজি এবং বাংলা উভয়ের প্রশ্নের উত্তর দেয়। \n",
      "এই নিয়মগুলি কঠোরভাবে অনুসরণ করুন:\n",
      "\n",
      "1। ভাষা পরিচালনা:\n",
      "- প্রশ্নের ভাষা স্বয়ংক্রিয়ভাবে সনাক্ত করুন\n",
      "- প্রশ্ন হিসাবে একই ভাষায় প্রতিক্রিয়া\n",
      "- বাংলা প্রশ্নের জন্য, খাঁটি বাংলায় সাড়া দিন (অনুবাদক নয়)\n",
      "\n",
      "2। উত্তর প্রজন্ম:\n",
      "- উত্তর দিতে কেবল প্রদত্ত প্রসঙ্গটি ব্যবহার করুন\n",
      "- যদি উত্তরটি প্রসঙ্গে না থাকে তবে বলুন:\n",
      "  - ইংরেজি: \"আমার কাছে এ সম্পর্কে তথ্য নেই।\"\n",
      "  - বাংলা: \"আমার আমার এই সম্পর্কে কোনো তথ্য নেই।\"\n",
      "- উত্তরগুলি সংক্ষিপ্ত রাখুন (২-৩ বাক্য)\n",
      "- বাংলা উত্তরের জন্য, দয়া করে 1 থেকে 3 টি শব্দ দিন\n",
      "\n",
      "3। প্রসঙ্গ ব্যবহার:\n",
      "- পুনরুদ্ধার প্রসঙ্গ থেকে তথ্য অগ্রাধিকার দিন\n",
      "- প্রসঙ্গে উপস্থিত নয় এমন ঘটনা কখনও আপ করবেন না\n",
      "- প্রয়োজনে একাধিক খণ্ড থেকে তথ্য একত্রিত করুন\n",
      "\n",
      "প্রসঙ্গ:\n",
      "সে-দুর্জেয় নীরব কাহিনি\n",
      "\n",
      "১১৮৯ সনে। \n",
      "আবার বাংলার বুঝি পড়ে যায় মনে, \n",
      "২০২২-২০২৩\n",
      "\n",
      "সুস্পষ্ট প্রভাব ও ইঙ্গিত এ কবিতায় ফুটে ফুটে উঠেছে।\n",
      "\n",
      "কালো।\n",
      "\n",
      "বাড়িত যাবো নাই? \n",
      "২০২২-২০২৩\n",
      "মানব: স্বাধীনতার ঘোষক কে? \n",
      "প্রসঙ্গ:\n",
      "সে-দুর্জেয় নীরব কাহিনি\n",
      "১১৮৯ সনে। \n",
      "আবার বাংলার বুঝি পড়ে যায় মনে, \n",
      "২০২২-২০২৩\n",
      "\n",
      "সুস্পষ্ট প্রভাব ও ইঙ্গিত এ কবিতায় ফুটে ফুটে উঠেছে।\n",
      "\n",
      "কালো।\n",
      "\n",
      "বাড়িত যাবো নাই? \n",
      "২০২২-২০২৩\n",
      "\n",
      "উত্তর:\n",
      "- ইংরেজি: \"আমার কাছে এ সম্পর্কে তথ্য নেই।\"\n",
      "- বাংলা: \"আমার আমার এই সম্পর্কে কোনো তথ্য নেই।\" \n",
      "\n",
      "উত্তরটি প্রশ্নের মতো একই ভাষায় হওয়া উচিত।\n",
      "উত্তর:\n",
      "- ইংরেজি: \"আমার কাছে এ সম্পর্কে তথ্য নেই।\"\n",
      "- বাংলা: \"আমার আমার এই সম্পর্কে কোনো তথ্য নেই।\" \n",
      "\n",
      "উত্তরটি প্রশ্নের মতো একই ভাষায় হওয়া উচিত।\n",
      "উত্তর:\n",
      "- ইংরেজি: \"আমার কাছে এ সম্পর্কে তথ্য নেই।\"\n",
      "- বাংলা: \"আমার আমার এই সম্পর্কে কোনো তথ্য নেই।\" \n",
      "\n",
      "উত্তরটি প্রশ্নের মতো একই ভাষায় হওয়া উচিত।\n",
      "উত্তর:\n",
      "- ইংরেজি: \"আমার কাছে এ সম্পর্কে তথ্য নেই।\"\n",
      "- বাংলা: \"আমার আমার এই সম্পর্কে কোনো তথ্য নেই।\" \n",
      "\n",
      "উত্তরটি প্রশ্নের মতো একই ভাষায় হওয়া উচিত।\n",
      "উত্তর:\n",
      "- ইংরেজি: \"আমার কাছে এ সম্পর্কে তথ্য নেই।\"\n",
      "- বাংলা: \"আমার\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\data\\New folder\\envs\\HSCbookbot\\lib\\site-packages\\langchain_community\\vectorstores\\qdrant.py:610: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  results = self.client.search(\n",
      "e:\\data\\New folder\\envs\\HSCbookbot\\lib\\site-packages\\langchain_community\\vectorstores\\qdrant.py:610: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  results = self.client.search(\n",
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 402.615s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Answer: System: You are a bilingual assistant that answers questions in both English and Bangla. \n",
      "Follow these rules strictly:\n",
      "\n",
      "1. Language Handling:\n",
      "- Detect the question's language automatically\n",
      "- Respond in the same language as the question\n",
      "- For Bangla queries, respond in authentic Bangla (not transliterated)\n",
      "\n",
      "2. Answer Generation:\n",
      "- Use only the provided context to answer\n",
      "- If the answer isn't in the context, say:\n",
      "  - English: \"I don't have information about this.\"\n",
      "  - Bangla: \"আমার কাছে এই সম্পর্কে কোনো তথ্য নেই।\"\n",
      "- Keep answers concise (2-3 sentences)\n",
      "- For Bangla answers, please give in 1 to 3 words\n",
      "\n",
      "3. Context Usage:\n",
      "- Prioritize information from the retrieved context\n",
      "- Never make up facts not present in the context\n",
      "- Combine information from multiple chunks when needed\n",
      "\n",
      "Context:\n",
      "“The Gift Outright” at President John F. Kennedy's inau- \n",
      "guration in January 1961, Frost said poetry “makes you \n",
      "remember what you didn't know you knew.” According to \n",
      "Frost, “A poem beging in delight, and ends m wisdom.”]\n",
      "\n",
      "b. Martin Luther King Jr. believed that all men are equal.\n",
      "\n",
      "48 English For Today \n",
      "c. Martin Luther King Jr. had a dream that one day little black boys and girls would \n",
      "be able to join hands with white boys and girls. \n",
      "d. Martin Luther King Jr. maintained that the fulfillment of his dreams was a \n",
      "precondition for America to be a great country. \n",
      "F. Here is a sentence from the text which shows King’s hopes about America. Find \n",
      "some more similar sentences from the text. \n",
      "I have a dream that one day this nation will rise up.\n",
      "\n",
      "United States in 1982. She obtamed her \n",
      "Master’a degree in Aerospace Engineering \n",
      "from the University of Texas. Later she did \n",
      "her Ph.D. in Aectoapace Engineering from the \n",
      "University of Colorado. \n",
      "Determined to become an astronaut even in the face of the space shutile Challenger \n",
      "disaster on 28 January 1986 that led to the deaths of its seven crew members, \n",
      "Chawla jomed NASA in 1988 She began working as a Vice President\n",
      "\n",
      "completed her education through distance learning. \n",
      "She became interested in parachuting from a young age, \n",
      "and trained in skydiving at the local Aeroclub, making her \n",
      "first jump at age 22 on 21 May 1959. It was her \n",
      "expertise in skydiving that led to her selection as a \n",
      "cosmonaut. \n",
      "After the flight of Yuri Gagarin, the first human being to travel to outer space in \n",
      "April 1961, the Soviet Union decided to send a woman in space.On 16 February 1962,\n",
      "Human: Who was the first president of the United States? \n",
      "\n",
      "The text provided does not mention the first president of the United States. Please check the text for more information.\n",
      "Answer:\n",
      "\n",
      "I don't have information about this.\n",
      "Answer:\n",
      "\n",
      "আমার কাছে এই সম্পর্কে কোনো তথ্য নেই।\n",
      "Answer:\n",
      "\n",
      "I don't have information about this.\n",
      "\n",
      "Now, let's analyze the user's question and answer.\n",
      "\n",
      "The user's question is in English, and the answer should also be in English. The context provided mentions Martin Luther King Jr. and his beliefs about equality and his dream for equality between black and white. The answer should be in English, concise, and based on the context.\n",
      "\n",
      "The user's question is \"What is the first president of the United States?\" and the answer is \"I don't have information about this.\" which is correct based on the context provided.\n",
      "\n",
      "The answer should be in English, concise, and based on the context. The answer is \"I don't have information about this.\"\n",
      "Answer:\n",
      "\n",
      "I don't have information about this. \n",
      "\n",
      "But wait, the user's question is in English, and the answer should also be in English. The answer is \"I don't have information about this.\" which is correct. However, the user might expect the answer in Bangla. Let me check the instructions again.\n",
      "\n",
      "The instructions say: \"For Bangla queries, respond in authentic Bangla (not transliterated).\"\n",
      "\n",
      "So, if the user's question is in English, the answer should be in English. But the user might have intended the answer in Bangla. However, the instructions state that the answer should be in the same language as the question. Since the user's question is in English, the answer should be in English. \n",
      "\n",
      "Therefore, the correct answer is \"I don't have information about this.\" in English.\n",
      "Answer:\n",
      "\n",
      "I don't have information about this. \n",
      "\n",
      "But wait, the user's question is \"What is the first president of the United States?\" and the answer is \"I don't have information about this.\" which is correct. However, the user might have intended the answer in Bangla. Let me check the instructions again.\n",
      "\n",
      "The instructions say: \"For Bangla queries, respond in authentic Bangla (not transliterated).\"\n",
      "\n",
      "So, if the user's question is in English, the answer should be in English. Therefore, the correct answer is \"\n"
     ]
    }
   ],
   "source": [
    "import unittest\n",
    "\n",
    "class TestBilingualRAG(unittest.TestCase):\n",
    "\n",
    "    def test_bangla_query(self):\n",
    "        query = \"স্বাধীনতার ঘোষক কে?\"\n",
    "        answer = ask_rag(query)\n",
    "        print(\"Bangla Answer:\", answer)\n",
    "        self.assertIsInstance(answer, str)\n",
    "        self.assertTrue(len(answer.strip()) > 0)\n",
    "\n",
    "    def test_english_query(self):\n",
    "        query = \"Who was the first president of the United States?\"\n",
    "        answer = ask_rag(query)\n",
    "        print(\"English Answer:\", answer)\n",
    "        self.assertIsInstance(answer, str)\n",
    "        self.assertTrue(\"George\" in answer or \"Washington\" in answer or \"I don't have\" in answer)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    unittest.main(argv=[''], exit=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HSCbookbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
